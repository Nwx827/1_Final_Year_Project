{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ffd570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils.preprocessing import load_and_clean_data\n",
    "\n",
    "df = load_and_clean_data(\"data/raw/IMDB Dataset.csv\")\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['review'], df['sentiment'], test_size=0.2, random_state=42, stratify=df['sentiment'])\n",
    "\n",
    "# Encode labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84ad37db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.89      0.90      5000\n",
      "    positive       0.89      0.90      0.90      5000\n",
      "\n",
      "    accuracy                           0.90     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# SVM Pipeline\n",
    "svm_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features=10000, ngram_range=(1,2))),\n",
    "    ('clf', LinearSVC())\n",
    "])\n",
    "\n",
    "svm_pipeline.fit(X_train, y_train)\n",
    "svm_preds = svm_pipeline.predict(X_test)\n",
    "\n",
    "print(\"SVM Performance:\")\n",
    "print(classification_report(y_test, svm_preds, target_names=le.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f304e925",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.86      0.85      5000\n",
      "    positive       0.85      0.84      0.85      5000\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.85      0.85      0.85     10000\n",
      "weighted avg       0.85      0.85      0.85     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Pipeline\n",
    "rf_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features=10000)),\n",
    "    ('clf', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "rf_preds = rf_pipeline.predict(X_test)\n",
    "\n",
    "print(\"Random Forest Performance:\")\n",
    "print(classification_report(y_test, rf_preds, target_names=le.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05fb576c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model/ML/rf_model.joblib']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(svm_pipeline, 'model/ML/svm_model.joblib')\n",
    "joblib.dump(rf_pipeline, 'model/ML/rf_model.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79688886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Type: <class 'sklearn.pipeline.Pipeline'>\n",
      "Model Parameters: {'memory': None, 'steps': [('tfidf', TfidfVectorizer(max_features=10000, ngram_range=(1, 2))), ('clf', LinearSVC())], 'verbose': False, 'tfidf': TfidfVectorizer(max_features=10000, ngram_range=(1, 2)), 'clf': LinearSVC(), 'tfidf__analyzer': 'word', 'tfidf__binary': False, 'tfidf__decode_error': 'strict', 'tfidf__dtype': <class 'numpy.float64'>, 'tfidf__encoding': 'utf-8', 'tfidf__input': 'content', 'tfidf__lowercase': True, 'tfidf__max_df': 1.0, 'tfidf__max_features': 10000, 'tfidf__min_df': 1, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l2', 'tfidf__preprocessor': None, 'tfidf__smooth_idf': True, 'tfidf__stop_words': None, 'tfidf__strip_accents': None, 'tfidf__sublinear_tf': False, 'tfidf__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b', 'tfidf__tokenizer': None, 'tfidf__use_idf': True, 'tfidf__vocabulary': None, 'clf__C': 1.0, 'clf__class_weight': None, 'clf__dual': 'warn', 'clf__fit_intercept': True, 'clf__intercept_scaling': 1, 'clf__loss': 'squared_hinge', 'clf__max_iter': 1000, 'clf__multi_class': 'ovr', 'clf__penalty': 'l2', 'clf__random_state': None, 'clf__tol': 0.0001, 'clf__verbose': 0}\n",
      "Model Type: <class 'sklearn.pipeline.Pipeline'>\n",
      "Model Coefficients: [[ 0.74268635  0.75419667 -0.35420303 ...  0.13324316 -0.82490941\n",
      "  -0.29342561]]\n",
      "Model Intercept: [-0.05697051]\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Load the pipeline model\n",
    "svm_model = joblib.load('model/ML/svm_model.joblib')\n",
    "\n",
    "# 1. Check the model type (this will show it's a pipeline)\n",
    "print(f\"Model Type: {type(svm_model)}\")\n",
    "\n",
    "# 2. Check the model's parameters (hyperparameters)\n",
    "print(f\"Model Parameters: {svm_model.get_params()}\")\n",
    "\n",
    "# 3. Access the classifier inside the pipeline (LinearSVC) and check coefficients and intercept\n",
    "svm_classifier = svm_model.named_steps['clf']\n",
    "\n",
    "# Check the coefficients (weights for each feature)\n",
    "if hasattr(svm_classifier, 'coef_'):\n",
    "    print(f\"Model Coefficients: {svm_classifier.coef_}\")\n",
    "\n",
    "# Check the intercept (bias term)\n",
    "if hasattr(svm_classifier, 'intercept_'):\n",
    "    print(f\"Model Intercept: {svm_classifier.intercept_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "659b898a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Type: <class 'sklearn.pipeline.Pipeline'>\n",
      "Model Parameters: {'memory': None, 'steps': [('tfidf', TfidfVectorizer(max_features=10000)), ('clf', RandomForestClassifier(random_state=42))], 'verbose': False, 'tfidf': TfidfVectorizer(max_features=10000), 'clf': RandomForestClassifier(random_state=42), 'tfidf__analyzer': 'word', 'tfidf__binary': False, 'tfidf__decode_error': 'strict', 'tfidf__dtype': <class 'numpy.float64'>, 'tfidf__encoding': 'utf-8', 'tfidf__input': 'content', 'tfidf__lowercase': True, 'tfidf__max_df': 1.0, 'tfidf__max_features': 10000, 'tfidf__min_df': 1, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l2', 'tfidf__preprocessor': None, 'tfidf__smooth_idf': True, 'tfidf__stop_words': None, 'tfidf__strip_accents': None, 'tfidf__sublinear_tf': False, 'tfidf__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b', 'tfidf__tokenizer': None, 'tfidf__use_idf': True, 'tfidf__vocabulary': None, 'clf__bootstrap': True, 'clf__ccp_alpha': 0.0, 'clf__class_weight': None, 'clf__criterion': 'gini', 'clf__max_depth': None, 'clf__max_features': 'sqrt', 'clf__max_leaf_nodes': None, 'clf__max_samples': None, 'clf__min_impurity_decrease': 0.0, 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 2, 'clf__min_weight_fraction_leaf': 0.0, 'clf__n_estimators': 100, 'clf__n_jobs': None, 'clf__oob_score': False, 'clf__random_state': 42, 'clf__verbose': 0, 'clf__warm_start': False}\n",
      "Feature Importances: [2.52017716e-05 1.23529399e-05 4.87399047e-05 ... 9.45158985e-05\n",
      " 4.29811424e-05 4.47645627e-06]\n",
      "Number of Estimators (Trees): 100\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Load the Random Forest pipeline model\n",
    "rf_pipeline = joblib.load('model/ML/rf_model.joblib')\n",
    "\n",
    "# 1. Check the model type (this will show it's a pipeline)\n",
    "print(f\"Model Type: {type(rf_pipeline)}\")\n",
    "\n",
    "# 2. Check the model's parameters (hyperparameters)\n",
    "print(f\"Model Parameters: {rf_pipeline.get_params()}\")\n",
    "\n",
    "# 3. Access the classifier inside the pipeline (RandomForestClassifier) and check feature importances and other attributes\n",
    "rf_classifier = rf_pipeline.named_steps['clf']  # Assuming your pipeline step is named 'clf'\n",
    "\n",
    "# Check the feature importances (weights for each feature)\n",
    "if hasattr(rf_classifier, 'feature_importances_'):\n",
    "    print(f\"Feature Importances: {rf_classifier.feature_importances_}\")\n",
    "\n",
    "# Check the number of estimators (trees in the Random Forest)\n",
    "if hasattr(rf_classifier, 'n_estimators'):\n",
    "    print(f\"Number of Estimators (Trees): {rf_classifier.n_estimators}\")\n",
    "\n",
    "# Optionally, check out-of-bag error score (if enabled)\n",
    "if hasattr(rf_classifier, 'oob_score_'):\n",
    "    print(f\"Out-of-Bag Score: {rf_classifier.oob_score_}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
